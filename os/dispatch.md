# 调度

- [调度](#调度)
  - [虚拟内存管理](#虚拟内存管理)
    - [**一、虚拟内存与物理内存**](#一虚拟内存与物理内存)
    - [**二、两个进程访问 `0x10086` 的情况**](#二两个进程访问-0x10086-的情况)
      - [1. **独立虚拟地址空间**](#1-独立虚拟地址空间)
      - [2. **共享内存**](#2-共享内存)
      - [3. **未映射地址**](#3-未映射地址)
    - [**三、具体场景分析**](#三具体场景分析)
      - [1. **独立进程**](#1-独立进程)
      - [2. **共享内存**](#2-共享内存-1)
      - [3. **未映射地址**](#3-未映射地址-1)
    - [**四、代码示例**](#四代码示例)
      - [1. **独立进程**](#1-独立进程-1)
      - [2. **共享内存**](#2-共享内存-2)
    - [**五、总结**](#五总结)
  - [共享内存](#共享内存)
    - [**一、共享内存的原理**](#一共享内存的原理)
    - [**二、共享内存的通信步骤**](#二共享内存的通信步骤)
      - [1. **创建共享内存段**](#1-创建共享内存段)
      - [2. **映射共享内存**](#2-映射共享内存)
      - [3. **读写共享内存**](#3-读写共享内存)
      - [4. **分离共享内存**](#4-分离共享内存)
      - [5. **删除共享内存**](#5-删除共享内存)
    - [**三、共享内存的示例代码**](#三共享内存的示例代码)
      - [**写入进程（writer.c）**](#写入进程writerc)
      - [**读取进程（reader.c）**](#读取进程readerc)
    - [**四、共享内存的同步机制**](#四共享内存的同步机制)
    - [**五、共享内存的优缺点**](#五共享内存的优缺点)
      - [**优点**：](#优点)
      - [**缺点**：](#缺点)
    - [**六、总结**](#六总结)
  - [多进程](#多进程)
    - [**一、虚拟地址空间**](#一虚拟地址空间)
      - [1. **独立虚拟地址空间**](#1-独立虚拟地址空间-1)
      - [2. **示例**](#2-示例)
    - [**二、共享内存**](#二共享内存)
      - [1. **共享内存机制**](#1-共享内存机制)
      - [2. **访问行为**](#2-访问行为)
      - [3. **示例**](#3-示例)
    - [**三、竞争条件**](#三竞争条件)
      - [示例（使用互斥锁）](#示例使用互斥锁)
    - [**四、总结**](#四总结)
  - [创建进程](#创建进程)
    - [**一、`fork()`**](#一fork)
      - [1. **功能**](#1-功能)
      - [2. **返回值**](#2-返回值)
      - [3. **示例**](#3-示例-1)
    - [**二、`exec()` 系列函数**](#二exec-系列函数)
      - [1. **功能**](#1-功能-1)
      - [2. **常见函数**](#2-常见函数)
      - [3. **示例**](#3-示例-2)
    - [**三、`fork()` + `exec()` 的典型流程**](#三fork--exec-的典型流程)
      - [示例](#示例)
    - [**四、其他相关系统调用**](#四其他相关系统调用)
    - [**五、总结**](#五总结-1)
  - [进程与CPU](#进程与cpu)
    - [**一、`sleep()` 函数的作用**](#一sleep-函数的作用)
    - [**二、B 进程的行为分析**](#二b-进程的行为分析)
    - [**三、CPU 占用率的计算**](#三cpu-占用率的计算)
    - [**四、A 进程的影响**](#四a-进程的影响)
    - [**五、总结**](#五总结-2)
    - [**六、示例代码**](#六示例代码)
      - [A 进程](#a-进程)
      - [B 进程](#b-进程)
    - [**七、测试方法**](#七测试方法)
  - [CPU抢占](#cpu抢占)
    - [**一、单核 CPU**](#一单核-cpu)
      - [1. **时间片轮转调度**](#1-时间片轮转调度)
      - [2. **A 和 B 进程的运行情况**](#2-a-和-b-进程的运行情况)
      - [3. **示例**](#3-示例-3)
    - [**二、多核 CPU**](#二多核-cpu)
      - [1. **并行运行**](#1-并行运行)
      - [2. **A 和 B 进程的运行情况**](#2-a-和-b-进程的运行情况-1)
      - [3. **示例**](#3-示例-4)
    - [**三、调度策略的影响**](#三调度策略的影响)
      - [1. **优先级**](#1-优先级)
      - [2. **I/O 阻塞**](#2-io-阻塞)
      - [3. **实时调度**](#3-实时调度)
    - [**四、总结**](#四总结-1)
    - [**五、测试方法**](#五测试方法)
  - [调度策略](#调度策略)
    - [**一、单核 CPU**](#一单核-cpu-1)
      - [1. **A 进程占用 100% CPU**](#1-a-进程占用-100-cpu)
      - [2. **B 进程能否上 CPU**](#2-b-进程能否上-cpu)
      - [3. **CPU 占用率**](#3-cpu-占用率)
      - [4. **示例**](#4-示例)
    - [**二、多核 CPU**](#二多核-cpu-1)
      - [1. **A 进程占用 100% CPU**](#1-a-进程占用-100-cpu-1)
      - [2. **B 进程能否上 CPU**](#2-b-进程能否上-cpu-1)
      - [3. **CPU 占用率**](#3-cpu-占用率-1)
      - [4. **示例**](#4-示例-1)
    - [**三、调度策略的影响**](#三调度策略的影响-1)
      - [1. **优先级**](#1-优先级-1)
      - [2. **I/O 阻塞**](#2-io-阻塞-1)
      - [3. **实时调度**](#3-实时调度-1)
    - [**四、总结**](#四总结-2)
    - [**五、测试方法**](#五测试方法-1)
  - [线程调度的过程](#线程调度的过程)
    - [**一、线程调度的基本概念**](#一线程调度的基本概念)
    - [**二、线程调度的过程**](#二线程调度的过程)
      - [1. **触发调度的事件**](#1-触发调度的事件)
      - [2. **调度器的决策**](#2-调度器的决策)
      - [3. **上下文切换**](#3-上下文切换)
      - [4. **恢复执行**](#4-恢复执行)
    - [**三、线程调度的示例**](#三线程调度的示例)
      - [1. **时间片轮转调度**](#1-时间片轮转调度-1)
      - [2. **优先级调度**](#2-优先级调度)
    - [**四、线程调度的优化**](#四线程调度的优化)
    - [**五、总结**](#五总结-3)
  - [线程被换下CPU的状态转变](#线程被换下cpu的状态转变)
    - [**一、线程的状态**](#一线程的状态)
    - [**二、线程换下处理机的状态转变**](#二线程换下处理机的状态转变)
      - [1. **时间片用完**](#1-时间片用完)
      - [2. **线程阻塞**](#2-线程阻塞)
      - [3. **线程终止**](#3-线程终止)
    - [**三、上下文切换的详细过程**](#三上下文切换的详细过程)
      - [1. **保存当前线程的上下文**](#1-保存当前线程的上下文)
      - [2. **选择下一个线程**](#2-选择下一个线程)
      - [3. **加载下一个线程的上下文**](#3-加载下一个线程的上下文)
      - [4. **切换到下一个线程**](#4-切换到下一个线程)
    - [**四、示例**](#四示例)
      - [1. **线程 A 运行**](#1-线程-a-运行)
      - [2. **时间片用完**](#2-时间片用完)
      - [3. **线程 B 运行**](#3-线程-b-运行)
    - [**五、总结**](#五总结-4)
  - [进程通信与调度](#进程通信与调度)
    - [**一、线程调度算法**](#一线程调度算法)
    - [**二、线程阻塞的时机**](#二线程阻塞的时机)
    - [**三、Linux 的线程调度算法**](#三linux-的线程调度算法)
    - [**四、多进程通信（IPC）的方式**](#四多进程通信ipc的方式)
    - [**五、两个进程通过 Socket 通信的过程**](#五两个进程通过-socket-通信的过程)
    - [**六、Socket 通信中的缓冲区拷贝次数**](#六socket-通信中的缓冲区拷贝次数)
    - [**七、共享内存通信的原理**](#七共享内存通信的原理)
      - [**示例代码（Linux）**：](#示例代码linux)
    - [**总结**](#总结)
  - [shgmet vs mmap](#shgmet-vs-mmap)
    - [**一、`shmget`（System V 共享内存）**](#一shmgetsystem-v-共享内存)
      - [**1. 功能与特点**](#1-功能与特点)
      - [**2. 核心 API**](#2-核心-api)
      - [**3. 使用示例**](#3-使用示例)
      - [**4. 优点与缺点**](#4-优点与缺点)
    - [**二、`mmap`（内存映射）**](#二mmap内存映射)
      - [**1. 功能与特点**](#1-功能与特点-1)
      - [**2. 核心 API**](#2-核心-api-1)
      - [**3. 使用示例**](#3-使用示例-1)
      - [**4. 优点与缺点**](#4-优点与缺点-1)
    - [**三、`shmget` 与 `mmap` 的关键对比**](#三shmget-与-mmap-的关键对比)
    - [**四、选型建议**](#四选型建议)
    - [**五、高级用法：结合 `mmap` 与共享内存**](#五高级用法结合-mmap-与共享内存)
    - [**六、总结**](#六总结-1)
  - [进程和线程的区别，进程切换上下文的成本](#进程和线程的区别进程切换上下文的成本)
    - [**一、进程和线程的核心区别**](#一进程和线程的核心区别)
    - [**二、进程切换上下文的成本**](#二进程切换上下文的成本)
      - [1. **什么是上下文切换？**](#1-什么是上下文切换)
      - [2. **进程切换的成本为何高？**](#2-进程切换的成本为何高)
      - [3. **线程切换的成本为何低？**](#3-线程切换的成本为何低)
    - [**三、上下文切换的具体开销**](#三上下文切换的具体开销)
    - [**四、如何减少上下文切换的开销？**](#四如何减少上下文切换的开销)
    - [**五、进程和线程的适用场景**](#五进程和线程的适用场景)
    - [**六、总结**](#六总结-2)
  - [进程和线程的关系，一个进程一定拥有一个线程吗](#进程和线程的关系一个进程一定拥有一个线程吗)
    - [**一、进程和线程的关系**](#一进程和线程的关系)
      - [1. **进程**](#1-进程)
      - [2. **线程**](#2-线程)
      - [3. **关系**](#3-关系)
    - [**二、一个进程是否一定拥有一个线程？**](#二一个进程是否一定拥有一个线程)
      - [1. **传统进程模型**](#1-传统进程模型)
      - [2. **多线程进程模型**](#2-多线程进程模型)
      - [3. **结论**](#3-结论)
    - [**三、进程和线程的创建**](#三进程和线程的创建)
      - [1. **进程创建**](#1-进程创建)
      - [2. **线程创建**](#2-线程创建)
    - [**四、示例**](#四示例-1)
      - [1. **单线程进程**](#1-单线程进程)
      - [2. **多线程进程**](#2-多线程进程)
    - [**五、总结**](#五总结-5)
  - [子进程和父进程的关系，fork的复制都是复制了什么？](#子进程和父进程的关系fork的复制都是复制了什么)
    - [**一、子进程和父进程的关系**](#一子进程和父进程的关系)
      - [1. **创建方式**](#1-创建方式)
      - [2. **关系**](#2-关系)
    - [**二、`fork()` 复制的内容**](#二fork-复制的内容)
      - [1. **地址空间**](#1-地址空间)
      - [2. **文件描述符**](#2-文件描述符)
      - [3. **信号处理**](#3-信号处理)
      - [4. **环境变量**](#4-环境变量)
      - [5. **进程属性**](#5-进程属性)
      - [6. **未继承的内容**](#6-未继承的内容)
    - [**三、`fork()` 的返回值**](#三fork-的返回值)
      - [示例代码](#示例代码)
    - [**四、`fork()` 的写时复制（COW）机制**](#四fork-的写时复制cow机制)
    - [**五、总结**](#五总结-6)
  - [子进程和线程的关系](#子进程和线程的关系)
    - [**一、子进程和线程的定义**](#一子进程和线程的定义)
      - [1. **子进程**](#1-子进程)
      - [2. **线程**](#2-线程-1)
    - [**二、子进程和线程的核心区别**](#二子进程和线程的核心区别)
    - [**三、子进程和线程的关系**](#三子进程和线程的关系)
      - [1. **资源共享**](#1-资源共享)
      - [2. **执行方式**](#2-执行方式)
      - [3. **通信机制**](#3-通信机制)
      - [4. **崩溃影响**](#4-崩溃影响)
    - [**四、示例代码**](#四示例代码)
      - [1. **子进程示例**](#1-子进程示例)
      - [2. **线程示例**](#2-线程示例)
    - [**五、适用场景**](#五适用场景)
    - [**六、总结**](#六总结-3)


---


## 虚拟内存管理
_如果两个进程都访问0x10086地址会发生什么_
当两个进程访问相同的虚拟地址（如 `0x10086`）时，实际访问的物理内存地址可能不同，这是因为现代操作系统使用 **虚拟内存管理** 机制。以下是详细解释：


### **一、虚拟内存与物理内存**
1. **虚拟内存**：
   - 每个进程都有自己的虚拟地址空间，范围通常为 `0x00000000` 到 `0xFFFFFFFF`（32 位系统）或更大（64 位系统）。
   - 虚拟地址由操作系统和硬件（MMU，内存管理单元）映射到物理内存。

2. **物理内存**：
   - 实际的硬件内存，由操作系统统一管理。
   - 不同进程的虚拟地址可能映射到相同的物理地址（共享内存），也可能映射到不同的物理地址。


### **二、两个进程访问 `0x10086` 的情况**
#### 1. **独立虚拟地址空间**
- 每个进程的虚拟地址空间是独立的。
- 进程 A 的 `0x10086` 和进程 B 的 `0x10086` 可能映射到不同的物理地址。

#### 2. **共享内存**
- 如果两个进程通过共享内存机制（如 `shmget` 和 `mmap`）共享同一块物理内存，则它们的 `0x10086` 可能映射到相同的物理地址。
- 此时，两个进程可以访问和修改同一块内存。

#### 3. **未映射地址**
- 如果 `0x10086` 未被映射到物理内存，访问该地址会导致 **段错误（Segmentation Fault）**。


### **三、具体场景分析**
#### 1. **独立进程**
- **进程 A** 和 **进程 B** 各自有自己的虚拟地址空间。
- 它们的 `0x10086` 映射到不同的物理地址。
- 修改 `0x10086` 的值不会影响另一个进程。

#### 2. **共享内存**
- **进程 A** 和 **进程 B** 通过共享内存机制共享同一块物理内存。
- 它们的 `0x10086` 映射到相同的物理地址。
- 修改 `0x10086` 的值会影响另一个进程。

#### 3. **未映射地址**
- 如果 `0x10086` 未被映射，访问该地址会导致段错误。
- 操作系统会终止访问该地址的进程。


### **四、代码示例**
#### 1. **独立进程**
```cpp
#include <iostream>
#include <unistd.h>

int main() {
    int* ptr = (int*)0x10086;
    *ptr = 42; // 可能导致段错误
    std::cout << "Value at 0x10086: " << *ptr << std::endl;
    return 0;
}
```
- 两个进程运行上述代码时，各自的 `0x10086` 映射到不同的物理地址。

#### 2. **共享内存**
```cpp
#include <iostream>
#include <sys/ipc.h>
#include <sys/shm.h>
#include <unistd.h>

int main() {
    // 创建共享内存
    int shmid = shmget(IPC_PRIVATE, 1024, 0666);
    int* ptr = (int*)shmat(shmid, nullptr, 0);

    // 映射到 0x10086
    ptr = (int*)0x10086;

    *ptr = 42; // 修改共享内存
    std::cout << "Value at 0x10086: " << *ptr << std::endl;

    // 分离共享内存
    shmdt(ptr);
    return 0;
}
```
- 两个进程运行上述代码时，它们的 `0x10086` 映射到相同的物理地址。


### **五、总结**
- 两个进程访问相同的虚拟地址（如 `0x10086`）时，实际访问的物理地址可能不同。
- 如果使用共享内存机制，两个进程可以访问相同的物理地址。
- 如果地址未映射，访问会导致段错误。

---
## 共享内存
_共享内存是怎么通信的_
**共享内存（Shared Memory）** 是一种高效的进程间通信（IPC）机制，允许多个进程共享同一块内存区域，从而直接读写数据，避免了频繁的系统调用和数据拷贝。以下是共享内存通信的详细原理和实现步骤：


### **一、共享内存的原理**
1. **共享内存段**：
   - 操作系统在内核中分配一块内存区域，多个进程可以将其映射到自己的地址空间。
   - 进程通过指针直接访问共享内存，无需通过内核。

2. **数据读写**：
   - 进程直接操作共享内存中的数据，读写速度非常快。

3. **同步机制**：
   - 由于多个进程可以同时访问共享内存，需要使用同步机制（如信号量、互斥锁）避免数据竞争。


### **二、共享内存的通信步骤**
#### 1. **创建共享内存段**
- 使用 `shmget()` 函数创建共享内存段。
- 参数：
  - `key`：共享内存的唯一标识（通常使用 `IPC_PRIVATE` 或 `ftok()` 生成）。
  - `size`：共享内存的大小。
  - `shmflg`：权限标志（如 `0666`）。

#### 2. **映射共享内存**
- 使用 `shmat()` 函数将共享内存映射到进程的地址空间。
- 参数：
  - `shmid`：共享内存段的 ID。
  - `shmaddr`：映射地址（通常为 `NULL`，由系统自动分配）。
  - `shmflg`：标志位（如 `SHM_RDONLY` 只读映射）。

#### 3. **读写共享内存**
- 进程通过指针直接访问共享内存中的数据。

#### 4. **分离共享内存**
- 使用 `shmdt()` 函数将共享内存从进程地址空间中分离。

#### 5. **删除共享内存**
- 使用 `shmctl()` 函数删除共享内存段。


### **三、共享内存的示例代码**
以下是一个简单的共享内存通信示例，包含两个进程：一个写入数据，另一个读取数据。

#### **写入进程（writer.c）**
```c
#include <sys/shm.h>
#include <sys/ipc.h>
#include <stdio.h>
#include <string.h>

int main() {
    // 创建共享内存
    int shmid = shmget(IPC_PRIVATE, 1024, 0666);
    if (shmid == -1) {
        perror("shmget");
        return 1;
    }

    // 映射共享内存
    char* shm = (char*)shmat(shmid, NULL, 0);
    if (shm == (char*)-1) {
        perror("shmat");
        return 1;
    }

    // 写入数据
    sprintf(shm, "Hello from Process A");

    // 分离共享内存
    shmdt(shm);

    printf("Data written to shared memory. Press Enter to delete shared memory.\n");
    getchar();

    // 删除共享内存
    shmctl(shmid, IPC_RMID, NULL);
    return 0;
}
```

#### **读取进程（reader.c）**
```c
#include <sys/shm.h>
#include <sys/ipc.h>
#include <stdio.h>

int main() {
    // 获取共享内存 ID（需要与写入进程一致）
    int shmid = shmget(IPC_PRIVATE, 1024, 0666);
    if (shmid == -1) {
        perror("shmget");
        return 1;
    }

    // 映射共享内存
    char* shm = (char*)shmat(shmid, NULL, 0);
    if (shm == (char*)-1) {
        perror("shmat");
        return 1;
    }

    // 读取数据
    printf("Data read from shared memory: %s\n", shm);

    // 分离共享内存
    shmdt(shm);
    return 0;
}
```


### **四、共享内存的同步机制**
由于多个进程可以同时访问共享内存，需要使用同步机制避免数据竞争。常见的同步机制包括：
1. **信号量（Semaphore）**：
   - 使用 `semget()`、`semop()` 控制对共享内存的访问。
2. **互斥锁（Mutex）**：
   - 使用 `pthread_mutex_t` 实现进程间的互斥访问。
3. **条件变量（Condition Variable）**：
   - 使用 `pthread_cond_t` 实现线程间的同步。


### **五、共享内存的优缺点**
#### **优点**：
1. **高效**：直接访问内存，无需系统调用和数据拷贝。
2. **灵活**：支持任意数据结构的共享。

#### **缺点**：
1. **同步复杂**：需要额外的同步机制避免数据竞争。
2. **资源管理**：共享内存的生命周期需要手动管理。


### **六、总结**
- 共享内存是一种高效的进程间通信机制，适合需要频繁数据交换的场景。
- 使用 `shmget()`、`shmat()`、`shmdt()` 和 `shmctl()` 函数管理共享内存。
- 需要配合同步机制（如信号量、互斥锁）保证数据一致性。

---
## 多进程
_父进程和子进程同时访问一个地址会发生什么_
当父进程和子进程同时访问同一个地址时，具体行为取决于访问的地址是 **虚拟地址** 还是 **共享内存**。以下是详细分析：

### **一、虚拟地址空间**
#### 1. **独立虚拟地址空间**
- **`fork()` 创建的子进程**：
  - 子进程是父进程的副本，拥有独立的虚拟地址空间。
  - 父进程和子进程的相同虚拟地址映射到不同的物理地址。
- **访问行为**：
  - 父进程和子进程访问相同的虚拟地址时，实际访问的是不同的物理内存。
  - 修改数据不会相互影响。

#### 2. **示例**
```c
#include <stdio.h>
#include <unistd.h>

int main() {
    int value = 42;
    pid_t pid = fork(); // 创建子进程

    if (pid == 0) {
        // 子进程
        value = 100;
        printf("Child process: value = %d\n", value);
    } else if (pid > 0) {
        // 父进程
        sleep(1); // 等待子进程修改
        printf("Parent process: value = %d\n", value);
    } else {
        perror("fork");
    }

    return 0;
}
```
- **输出**：
  ```
  Child process: value = 100
  Parent process: value = 42
  ```
- **解释**：
  - 子进程修改 `value` 不会影响父进程的 `value`，因为它们的虚拟地址空间是独立的。


### **二、共享内存**
#### 1. **共享内存机制**
- 父进程和子进程可以通过共享内存机制（如 `mmap` 或 `shmget`）共享同一块物理内存。
- 共享内存的虚拟地址可以相同，也可以不同。

#### 2. **访问行为**
- 父进程和子进程访问共享内存时，实际访问的是相同的物理内存。
- 修改数据会相互影响。

#### 3. **示例**
```c
#include <stdio.h>
#include <unistd.h>
#include <sys/mman.h>
#include <sys/wait.h>

int main() {
    // 创建共享内存
    int* shared_value = mmap(NULL, sizeof(int), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0);
    *shared_value = 42;

    pid_t pid = fork(); // 创建子进程

    if (pid == 0) {
        // 子进程
        *shared_value = 100;
        printf("Child process: shared_value = %d\n", *shared_value);
    } else if (pid > 0) {
        // 父进程
        wait(NULL); // 等待子进程结束
        printf("Parent process: shared_value = %d\n", *shared_value);
        munmap(shared_value, sizeof(int)); // 释放共享内存
    } else {
        perror("fork");
    }

    return 0;
}
```
- **输出**：
  ```
  Child process: shared_value = 100
  Parent process: shared_value = 100
  ```
- **解释**：
  - 父进程和子进程通过共享内存访问相同的物理地址，修改数据会相互影响。


### **三、竞争条件**
如果父进程和子进程同时访问共享内存，可能会发生 **竞争条件（Race Condition）**：
- 多个进程同时修改共享数据，导致结果不可预测。
- 需要使用同步机制（如互斥锁、信号量）避免竞争条件。

#### 示例（使用互斥锁）
```c
#include <stdio.h>
#include <unistd.h>
#include <sys/mman.h>
#include <sys/wait.h>
#include <pthread.h>

int main() {
    // 创建共享内存
    struct SharedData {
        int value;
        pthread_mutex_t mutex;
    };
    struct SharedData* shared_data = mmap(NULL, sizeof(struct SharedData), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0);
    shared_data->value = 42;
    pthread_mutex_init(&shared_data->mutex, NULL);

    pid_t pid = fork(); // 创建子进程

    if (pid == 0) {
        // 子进程
        pthread_mutex_lock(&shared_data->mutex);
        shared_data->value = 100;
        printf("Child process: value = %d\n", shared_data->value);
        pthread_mutex_unlock(&shared_data->mutex);
    } else if (pid > 0) {
        // 父进程
        pthread_mutex_lock(&shared_data->mutex);
        printf("Parent process: value = %d\n", shared_data->value);
        pthread_mutex_unlock(&shared_data->mutex);
        wait(NULL); // 等待子进程结束
        pthread_mutex_destroy(&shared_data->mutex);
        munmap(shared_data, sizeof(struct SharedData)); // 释放共享内存
    } else {
        perror("fork");
    }

    return 0;
}
```

### **四、总结**
1. **独立虚拟地址空间**：
   - 父进程和子进程访问相同的虚拟地址时，实际访问的是不同的物理内存。
   - 修改数据不会相互影响。

2. **共享内存**：
   - 父进程和子进程访问相同的物理内存。
   - 修改数据会相互影响，需使用同步机制避免竞争条件。

3. **竞争条件**：
   - 多个进程同时修改共享数据时，需使用互斥锁、信号量等同步机制。

---
## 创建进程
_操作系统创建进程的系统调用是什么_
在操作系统中，创建进程的系统调用通常是 **`fork()`** 和 **`exec()`** 系列函数。以下是它们的详细说明：

### **一、`fork()`**
#### 1. **功能**
- 创建一个新的进程（子进程），子进程是父进程的副本。
- 子进程和父进程在 `fork()` 之后的代码继续执行。

#### 2. **返回值**
- 在父进程中：返回子进程的 PID（进程 ID）。
- 在子进程中：返回 `0`。
- 如果失败：返回 `-1`。

#### 3. **示例**
```c
#include <stdio.h>
#include <unistd.h>

int main() {
    pid_t pid = fork(); // 创建子进程

    if (pid == 0) {
        // 子进程
        printf("Child process (PID: %d)\n", getpid());
    } else if (pid > 0) {
        // 父进程
        printf("Parent process (PID: %d), Child PID: %d\n", getpid(), pid);
    } else {
        // fork 失败
        perror("fork");
    }

    return 0;
}
```


### **二、`exec()` 系列函数**
#### 1. **功能**
- 替换当前进程的地址空间，加载一个新的程序并执行。
- 通常与 `fork()` 结合使用：先 `fork()` 创建子进程，然后在子进程中调用 `exec()` 加载新程序。

#### 2. **常见函数**
- `execl()`：参数列表形式。
- `execv()`：参数数组形式。
- `execle()`：带环境变量。
- `execvp()`：在 `PATH` 中查找可执行文件。

#### 3. **示例**
```c
#include <stdio.h>
#include <unistd.h>

int main() {
    pid_t pid = fork(); // 创建子进程

    if (pid == 0) {
        // 子进程
        execl("/bin/ls", "ls", "-l", NULL); // 替换为 ls 命令
        perror("execl"); // 如果 execl 失败
    } else if (pid > 0) {
        // 父进程
        printf("Parent process (PID: %d), Child PID: %d\n", getpid(), pid);
    } else {
        // fork 失败
        perror("fork");
    }

    return 0;
}
```


### **三、`fork()` + `exec()` 的典型流程**
1. **`fork()`**：创建子进程。
2. **`exec()`**：在子进程中加载新程序。
3. **父进程**：继续执行原有逻辑，或等待子进程完成。

#### 示例
```c
#include <stdio.h>
#include <unistd.h>
#include <sys/wait.h>

int main() {
    pid_t pid = fork(); // 创建子进程

    if (pid == 0) {
        // 子进程
        execl("/bin/ls", "ls", "-l", NULL); // 替换为 ls 命令
        perror("execl"); // 如果 execl 失败
    } else if (pid > 0) {
        // 父进程
        printf("Parent process (PID: %d), Child PID: %d\n", getpid(), pid);
        wait(NULL); // 等待子进程结束
        printf("Child process finished.\n");
    } else {
        // fork 失败
        perror("fork");
    }

    return 0;
}
```


### **四、其他相关系统调用**
1. **`wait()` 和 `waitpid()`**
   - 父进程等待子进程结束。
   - 示例：
     ```c
     wait(NULL); // 等待任意子进程结束
     waitpid(pid, &status, 0); // 等待指定子进程结束
     ```

2. **`clone()`**
   - 类似于 `fork()`，但可以更精细地控制资源共享（如内存、文件描述符）。
   - 通常用于实现线程。

3. **`vfork()`**
   - 创建一个子进程，但子进程与父进程共享地址空间，直到调用 `exec()` 或 `_exit()`。
   - 已逐渐被弃用，推荐使用 `fork()`。


### **五、总结**
- **`fork()`**：创建子进程，子进程是父进程的副本。
- **`exec()`**：替换当前进程的地址空间，加载新程序。
- **`fork()` + `exec()`**：典型的进程创建和执行流程。
- **`wait()`**：父进程等待子进程结束。


---
## 进程与CPU
_如果A进程是while(1)，B进程是sleep(1000); while(1)，那B进程的CPU占用是多少_
要分析 B 进程的 CPU 占用率，我们需要理解操作系统的进程调度机制以及 `sleep()` 函数的作用。


### **一、`sleep()` 函数的作用**
- `sleep(n)` 会让当前进程进入睡眠状态，暂停执行 `n` 秒。
- 在睡眠期间，进程不会占用 CPU 资源。
- 睡眠结束后，进程会被重新调度，继续执行后续代码。


### **二、B 进程的行为分析**
B 进程的代码如下：
```c
sleep(1000); // 睡眠 1000 秒
while (1) {}  // 无限循环
```

1. **睡眠阶段（前 1000 秒）**：
   - B 进程调用 `sleep(1000)`，进入睡眠状态。
   - 在睡眠期间，B 进程不会占用 CPU 资源。
   - CPU 占用率接近 **0%**。

2. **无限循环阶段（1000 秒后）**：
   - B 进程从睡眠中唤醒，进入 `while (1)` 无限循环。
   - 由于 `while (1)` 是一个空循环，B 进程会持续占用 CPU。
   - CPU 占用率接近 **100%**（单核情况下）。


### **三、CPU 占用率的计算**
1. **单核 CPU**：
   - 在无限循环阶段，B 进程会独占一个 CPU 核心。
   - CPU 占用率为 **100%**。

2. **多核 CPU**：
   - 假设系统有 `N` 个 CPU 核心。
   - 在无限循环阶段，B 进程会独占一个 CPU 核心。
   - CPU 占用率为 **100%/N**。


### **四、A 进程的影响**
A 进程的代码如下：
```c
while (1) {}  // 无限循环
```

1. **单核 CPU**：
   - A 进程和 B 进程会竞争 CPU 资源。
   - 操作系统通过时间片轮转调度两个进程。
   - 每个进程的 CPU 占用率约为 **50%**。

2. **多核 CPU**：
   - A 进程和 B 进程可以分别运行在不同的 CPU 核心上。
   - 每个进程的 CPU 占用率接近 **100%**。

### **五、总结**
1. **B 进程的 CPU 占用率**：
   - **前 1000 秒**：接近 **0%**（睡眠状态）。
   - **1000 秒后**：
     - 单核 CPU：接近 **100%**。
     - 多核 CPU：接近 **100%/N**（`N` 为 CPU 核心数）。

2. **A 进程的影响**：
   - 单核 CPU：A 和 B 进程各占约 **50%**。
   - 多核 CPU：A 和 B 进程各占接近 **100%**。

3. **实际测试**：
   - 可以使用 `top` 或 `htop` 命令查看进程的 CPU 占用率。

### **六、示例代码**
#### A 进程
```c
#include <stdio.h>

int main() {
    while (1) {} // 无限循环
    return 0;
}
```

#### B 进程
```c
#include <stdio.h>
#include <unistd.h>

int main() {
    sleep(1000); // 睡眠 1000 秒
    while (1) {} // 无限循环
    return 0;
}
```

### **七、测试方法**
1. 编译并运行 A 和 B 进程。
2. 使用 `top` 命令观察 CPU 占用率：
   ```bash
   top
   ```
3. 查看 B 进程的 CPU 占用率变化。

---
## CPU抢占
_如果A进程在CPU中运行，B进程能上CPU吗_
在操作系统中，**A 进程** 和 **B 进程** 能否同时在 CPU 上运行，取决于系统的 **CPU 核心数** 和 **调度策略**。以下是详细分析：


### **一、单核 CPU**
#### 1. **时间片轮转调度**
- 单核 CPU 一次只能运行一个进程。
- 操作系统通过 **时间片轮转（Round-Robin）** 调度算法，为每个进程分配一个时间片（如 10ms）。
- 当 A 进程的时间片用完时，操作系统会将其挂起，切换到 B 进程运行。

#### 2. **A 和 B 进程的运行情况**
- A 进程和 B 进程会交替运行。
- 每个进程的 CPU 占用率约为 **50%**（假设两个进程都是 `while (1)` 的无限循环）。

#### 3. **示例**
- A 进程运行 10ms，然后切换到 B 进程运行 10ms，依此类推。


### **二、多核 CPU**
#### 1. **并行运行**
- 多核 CPU 可以同时运行多个进程。
- 如果系统有 `N` 个 CPU 核心，则最多可以同时运行 `N` 个进程。

#### 2. **A 和 B 进程的运行情况**
- A 进程和 B 进程可以分别运行在不同的 CPU 核心上。
- 每个进程的 CPU 占用率接近 **100%**。

#### 3. **示例**
- 假设系统有 4 个 CPU 核心：
  - A 进程运行在核心 1 上。
  - B 进程运行在核心 2 上。
  - 其他核心可以运行其他进程。


### **三、调度策略的影响**
#### 1. **优先级**
- 操作系统会根据进程的优先级决定调度顺序。
- 高优先级的进程更容易获得 CPU 资源。

#### 2. **I/O 阻塞**
- 如果进程进入 I/O 阻塞状态（如等待磁盘或网络），操作系统会立即切换到其他进程。

#### 3. **实时调度**
- 实时操作系统（如 Linux 的实时内核）可以保证高优先级进程的实时性。


### **四、总结**
1. **单核 CPU**：
   - A 进程和 B 进程会交替运行。
   - 每个进程的 CPU 占用率约为 **50%**。

2. **多核 CPU**：
   - A 进程和 B 进程可以同时运行在不同的核心上。
   - 每个进程的 CPU 占用率接近 **100%**。

3. **调度策略**：
   - 优先级、I/O 阻塞和实时调度会影响进程的 CPU 占用情况。


### **五、测试方法**
1. 使用 `top` 或 `htop` 命令查看进程的 CPU 占用率：
   ```bash
   top
   ```
2. 查看 A 和 B 进程的 CPU 占用情况。

---
## 调度策略
_当A进程运行时，CPU占用率100%，那B进程能否上CPU_
当 **A 进程** 运行时，CPU 占用率达到 **100%**，**B 进程** 能否上 CPU 取决于以下因素：


### **一、单核 CPU**
#### 1. **A 进程占用 100% CPU**
- 如果 A 进程是一个无限循环（如 `while (1)`），它会持续占用 CPU。
- 在单核 CPU 上，操作系统通过 **时间片轮转调度** 来分配 CPU 资源。

#### 2. **B 进程能否上 CPU**
- **能**：操作系统会在 A 进程的时间片用完后，强制切换到 B 进程。
- **切换过程**：
  1. 保存 A 进程的上下文（如寄存器、程序计数器）。
  2. 加载 B 进程的上下文。
  3. 开始运行 B 进程。

#### 3. **CPU 占用率**
- A 进程和 B 进程会交替运行。
- 每个进程的 CPU 占用率约为 **50%**。

#### 4. **示例**
- A 进程运行 10ms，然后切换到 B 进程运行 10ms，依此类推。


### **二、多核 CPU**
#### 1. **A 进程占用 100% CPU**
- 如果 A 进程是一个无限循环，它会独占一个 CPU 核心。
- 其他 CPU 核心可以运行其他进程。

#### 2. **B 进程能否上 CPU**
- **能**：B 进程可以运行在其他空闲的 CPU 核心上。
- 如果系统有 `N` 个 CPU 核心，则最多可以同时运行 `N` 个进程。

#### 3. **CPU 占用率**
- A 进程占用一个核心的 **100%**。
- B 进程占用另一个核心的 **100%**。

#### 4. **示例**
- 假设系统有 4 个 CPU 核心：
  - A 进程运行在核心 1 上，占用 100%。
  - B 进程运行在核心 2 上，占用 100%。
  - 核心 3 和核心 4 可以运行其他进程。


### **三、调度策略的影响**
#### 1. **优先级**
- 如果 B 进程的优先级高于 A 进程，操作系统会优先调度 B 进程。
- 在极端情况下，A 进程可能会被完全剥夺 CPU 资源。

#### 2. **I/O 阻塞**
- 如果 A 进程进入 I/O 阻塞状态（如等待磁盘或网络），操作系统会立即切换到 B 进程。

#### 3. **实时调度**
- 实时操作系统（如 Linux 的实时内核）可以保证高优先级进程的实时性。


### **四、总结**
1. **单核 CPU**：
   - A 进程和 B 进程会交替运行。
   - 每个进程的 CPU 占用率约为 **50%**。

2. **多核 CPU**：
   - A 进程和 B 进程可以同时运行在不同的核心上。
   - 每个进程的 CPU 占用率接近 **100%**。

3. **调度策略**：
   - 优先级、I/O 阻塞和实时调度会影响进程的 CPU 占用情况。


### **五、测试方法**
1. 使用 `top` 或 `htop` 命令查看进程的 CPU 占用率：
   ```bash
   top
   ```
2. 查看 A 和 B 进程的 CPU 占用情况。

---
## 线程调度的过程
线程调度是操作系统内核的核心功能之一，负责决定哪个线程在何时使用 CPU 资源。以下是线程调度的详细过程：


### **一、线程调度的基本概念**
1. **线程**：
   - 线程是进程中的一个执行流，共享进程的资源（如内存、文件描述符）。
   - 线程是 CPU 调度的基本单位。

2. **调度器**：
   - 操作系统内核中的调度器负责管理线程的调度。
   - 调度器根据调度算法决定哪个线程获得 CPU 资源。

3. **上下文切换**：
   - 当调度器切换到另一个线程时，需要保存当前线程的上下文（如寄存器、程序计数器），并加载新线程的上下文。


### **二、线程调度的过程**
#### 1. **触发调度的事件**
- **时间片用完**：
  - 每个线程被分配一个时间片（如 10ms），时间片用完后，调度器会切换到另一个线程。
- **线程阻塞**：
  - 线程进入阻塞状态（如等待 I/O、锁、信号量），调度器会立即切换到其他可运行的线程。
- **线程终止**：
  - 线程执行完毕，调度器会切换到其他线程。
- **高优先级线程就绪**：
  - 如果有更高优先级的线程就绪，调度器可能会抢占当前线程。

#### 2. **调度器的决策**
- 调度器根据调度算法（如时间片轮转、优先级调度）选择一个就绪线程。
- 常见的调度算法：
  - **先来先服务（FCFS）**：按线程到达顺序调度。
  - **最短作业优先（SJF）**：优先调度执行时间最短的线程。
  - **时间片轮转（Round-Robin）**：每个线程分配一个时间片，轮流执行。
  - **优先级调度**：优先调度高优先级的线程。

#### 3. **上下文切换**
- **保存当前线程的上下文**：
  - 将当前线程的寄存器、程序计数器等状态保存到线程控制块（TCB）中。
- **加载新线程的上下文**：
  - 从新线程的 TCB 中加载寄存器、程序计数器等状态。
- **切换到新线程**：
  - 更新 CPU 的寄存器、程序计数器，开始执行新线程。

#### 4. **恢复执行**
- 新线程从上次暂停的位置继续执行。


### **三、线程调度的示例**
#### 1. **时间片轮转调度**
- 假设有两个线程 A 和 B，时间片为 10ms。
- 调度过程：
  1. 线程 A 运行 10ms，时间片用完。
  2. 调度器切换到线程 B。
  3. 线程 B 运行 10ms，时间片用完。
  4. 调度器切换回线程 A。

#### 2. **优先级调度**
- 假设线程 A 的优先级高于线程 B。
- 调度过程：
  1. 线程 A 运行，直到阻塞或时间片用完。
  2. 如果线程 A 阻塞，调度器切换到线程 B。
  3. 如果线程 A 就绪，调度器会抢占线程 B，切换回线程 A。


### **四、线程调度的优化**
1. **减少上下文切换开销**：
   - 使用轻量级线程（如协程）。
   - 优化调度算法，减少不必要的切换。

2. **负载均衡**：
   - 在多核 CPU 上，将线程均匀分配到各个核心。

3. **实时调度**：
   - 实时操作系统（如 Linux 的实时内核）可以保证高优先级线程的实时性。


### **五、总结**
- 线程调度的过程包括触发调度事件、调度器决策、上下文切换和恢复执行。
- 调度算法（如时间片轮转、优先级调度）决定了线程的执行顺序。
- 上下文切换是线程调度的核心操作，需要保存和恢复线程的状态。


---
## 线程被换下CPU的状态转变
当一个线程被换下处理机（CPU）时，它的状态会发生变化，同时操作系统会执行一系列操作来保存当前线程的上下文并加载下一个线程的上下文。以下是线程换下处理机时的状态转变和详细过程：


### **一、线程的状态**
线程在其生命周期中可能处于以下几种状态：
1. **就绪（Ready）**：
   - 线程已准备好运行，等待调度器分配 CPU。
2. **运行（Running）**：
   - 线程正在 CPU 上执行。
3. **阻塞（Blocked）**：
   - 线程因等待某些事件（如 I/O 完成、锁释放）而暂停执行。
4. **终止（Terminated）**：
   - 线程执行完毕或被强制终止。


### **二、线程换下处理机的状态转变**
当一个线程被换下处理机时，它的状态会从 **运行（Running）** 转变为 **就绪（Ready）** 或 **阻塞（Blocked）**，具体取决于换下的原因。

#### 1. **时间片用完**
- **状态转变**：运行 → 就绪。
- **原因**：线程的时间片用完，调度器切换到其他线程。
- **操作**：
  1. 保存当前线程的上下文（如寄存器、程序计数器）。
  2. 将线程状态设置为 **就绪**。
  3. 将线程放入就绪队列，等待下次调度。

#### 2. **线程阻塞**
- **状态转变**：运行 → 阻塞。
- **原因**：线程等待某些事件（如 I/O 完成、锁释放）。
- **操作**：
  1. 保存当前线程的上下文。
  2. 将线程状态设置为 **阻塞**。
  3. 将线程放入阻塞队列，等待事件完成。

#### 3. **线程终止**
- **状态转变**：运行 → 终止。
- **原因**：线程执行完毕或被强制终止。
- **操作**：
  1. 释放线程占用的资源（如内存、文件描述符）。
  2. 将线程状态设置为 **终止**。
  3. 从调度器中移除线程。


### **三、上下文切换的详细过程**
上下文切换是线程换下处理机的核心操作，包括以下步骤：

#### 1. **保存当前线程的上下文**
- 将当前线程的寄存器、程序计数器、栈指针等状态保存到线程控制块（TCB）中。
- 示例：
  - 保存通用寄存器（如 `eax`、`ebx`）。
  - 保存程序计数器（PC），记录线程的下一条指令地址。
  - 保存栈指针（SP），记录线程的栈位置。

#### 2. **选择下一个线程**
- 调度器根据调度算法（如时间片轮转、优先级调度）从就绪队列中选择一个线程。

#### 3. **加载下一个线程的上下文**
- 从下一个线程的 TCB 中加载寄存器、程序计数器、栈指针等状态。
- 示例：
  - 加载通用寄存器。
  - 加载程序计数器，恢复线程的执行位置。
  - 加载栈指针，恢复线程的栈。

#### 4. **切换到下一个线程**
- 更新 CPU 的寄存器、程序计数器，开始执行下一个线程。


### **四、示例**
假设有两个线程 A 和 B，时间片为 10ms。

#### 1. **线程 A 运行**
- 线程 A 的状态为 **运行**。
- 线程 B 的状态为 **就绪**。

#### 2. **时间片用完**
- 线程 A 的时间片用完，调度器切换到线程 B。
- 线程 A 的状态变为 **就绪**。
- 线程 B 的状态变为 **运行**。

#### 3. **线程 B 运行**
- 线程 B 运行 10ms，时间片用完。
- 调度器切换回线程 A。


### **五、总结**
- 线程换下处理机时，状态会从 **运行** 转变为 **就绪** 或 **阻塞**。
- 上下文切换是线程调度的核心操作，包括保存当前线程的上下文和加载下一个线程的上下文。

---
## 进程通信与调度

### **一、线程调度算法**
常见的线程调度算法包括：
1. **先来先服务（FCFS）**  
   - 按线程到达顺序调度，适合长作业，但可能导致短作业等待时间过长。

2. **最短作业优先（SJF）**  
   - 优先调度执行时间最短的线程，但需要预知作业时间，实际应用较少。

3. **时间片轮转（Round-Robin）**  
   - 每个线程分配固定时间片（如 10ms），轮流执行，公平但上下文切换开销大。

4. **优先级调度**  
   - 按优先级调度线程，高优先级线程可抢占低优先级线程的 CPU。

5. **多级反馈队列（MLFQ）**  
   - 结合时间片轮转和优先级调度，动态调整线程优先级。


### **二、线程阻塞的时机**
线程在以下场景会进入阻塞状态：
1. **等待 I/O 操作**（如文件读写、网络请求）。
2. **等待锁或信号量**（如 `pthread_mutex_lock`、`sem_wait`）。
3. **等待条件变量**（如 `pthread_cond_wait`）。
4. **主动休眠**（如 `sleep()`、`usleep()`）。
5. **等待子进程退出**（如 `wait()`）。


### **三、Linux 的线程调度算法**
Linux 使用 **完全公平调度器（CFS，Completely Fair Scheduler）**：
1. **核心思想**：  
   - 基于虚拟运行时间（`vruntime`）分配 CPU 时间，保证每个线程公平获得 CPU。
2. **数据结构**：  
   - 使用红黑树（Red-Black Tree）管理线程的 `vruntime`，快速选择最小 `vruntime` 的线程。
3. **权重机制**：  
   - 通过 `nice` 值调整线程优先级，`nice` 值越低（优先级越高）的线程获得更多 CPU 时间。
4. **实时调度**：  
   - 支持实时线程（如 `SCHED_FIFO`、`SCHED_RR`），可抢占普通线程。


### **四、多进程通信（IPC）的方式**
1. **管道（Pipe）**  
   - 单向通信，父子进程间使用，示例：`pipe()` + `fork()`。

2. **命名管道（FIFO）**  
   - 允许无关进程通过文件系统路径通信。

3. **消息队列（Message Queue）**  
   - 进程通过消息结构体通信，示例：`msgget()`、`msgsnd()`。

4. **共享内存（Shared Memory）**  
   - 进程共享同一块内存区域，需同步机制（如信号量）。

5. **信号量（Semaphore）**  
   - 控制对共享资源的访问，防止竞争条件。

6. **套接字（Socket）**  
   - 支持跨网络通信，示例：TCP/UDP 套接字。

7. **信号（Signal）**  
   - 通过发送信号（如 `SIGUSR1`）通知进程。


### **五、两个进程通过 Socket 通信的过程**
以 **TCP 套接字** 为例：
1. **服务端**：
   - `socket()`：创建套接字。
   - `bind()`：绑定 IP 和端口。
   - `listen()`：开始监听连接。
   - `accept()`：接受客户端连接，返回新套接字。
   - `read()`/`write()`：通过新套接字与客户端通信。

2. **客户端**：
   - `socket()`：创建套接字。
   - `connect()`：连接服务端。
   - `write()`/`read()`：发送和接收数据。


### **六、Socket 通信中的缓冲区拷贝次数**
1. **发送方**：
   - 用户空间 → 内核空间（1 次拷贝）。
2. **接收方**：
   - 内核空间 → 用户空间（1 次拷贝）。
3. **总拷贝次数**：  
   - **传统方式**：4 次（用户态 ↔ 内核态各 2 次）。
   - **零拷贝优化**（如 `sendfile()`）：2 次（内核态内部直接传输）。


### **七、共享内存通信的原理**
1. **创建共享内存**：  
   - 使用 `shmget()` 创建共享内存段。
   - 使用 `shmat()` 将共享内存映射到进程地址空间。

2. **数据读写**：  
   - 进程直接操作映射后的内存地址，无需系统调用。

3. **同步机制**：  
   - 需要配合信号量或互斥锁，防止数据竞争。

#### **示例代码（Linux）**：
```c
#include <sys/shm.h>
#include <sys/ipc.h>

int main() {
    // 创建共享内存
    int shmid = shmget(IPC_PRIVATE, 1024, 0666);
    char* shm = (char*)shmat(shmid, NULL, 0);

    // 写入数据
    sprintf(shm, "Hello from Process A");

    // 分离共享内存
    shmdt(shm);
    return 0;
}
```


### **总结**
- **线程调度算法**：CFS 是 Linux 的核心调度器，基于公平性和优先级。
- **进程通信**：共享内存速度最快，但需同步；Socket 适合跨网络通信。
- **Socket 通信**：涉及多次数据拷贝，零拷贝技术可优化性能。

---
## shgmet vs mmap
在 Linux 系统中，`shmget` 和 `mmap` 都用于实现进程间的内存共享，但它们的实现方式、使用场景和底层机制有所不同。以下是它们的核心区别与使用指南：

### **一、`shmget`（System V 共享内存）**
#### **1. 功能与特点**
- **用途**：创建或获取一个 System V 共享内存段，允许多个进程直接访问同一块物理内存。
- **生命周期**：
  - 共享内存段由内核管理，**显式释放**（`shmctl(IPC_RMID)`）或系统重启后才会销毁。
  - 即使所有进程都断开连接（`shmdt`），内存段仍存在，直到显式删除。
- **同步要求**：需结合信号量（`semget`）等机制保证数据一致性。

#### **2. 核心 API**
```c
#include <sys/shm.h>

// 创建或获取共享内存段
int shmget(key_t key, size_t size, int shmflg);

// 将共享内存附加到进程地址空间
void* shmat(int shmid, const void* shmaddr, int shmflg);

// 断开共享内存连接
int shmdt(const void* shmaddr);

// 控制共享内存段（如删除）
int shmctl(int shmid, int cmd, struct shmid_ds* buf);
```

#### **3. 使用示例**
```c
key_t key = ftok("/tmp", 'A');
int shmid = shmget(key, 4096, IPC_CREAT | 0666); // 创建 4KB 共享内存
char* data = (char*)shmat(shmid, NULL, 0);
sprintf(data, "Hello from PID %d", getpid());     // 写入数据
shmdt(data);                                      // 断开连接
// 删除共享内存（可选）
shmctl(shmid, IPC_RMID, NULL);
```

#### **4. 优点与缺点**
- **优点**：
  - 共享内存直接映射到进程空间，访问速度快。
  - 适合大规模数据共享（如进程间频繁交换数据）。
- **缺点**：
  - 依赖 System V 接口，跨平台兼容性较差。
  - 需要手动管理生命周期，容易导致内存泄漏。


### **二、`mmap`（内存映射）**
#### **1. 功能与特点**
- **用途**：将文件或匿名内存映射到进程的虚拟地址空间，支持共享或私有映射。
- **生命周期**：
  - 若映射到文件，内存内容可持久化到磁盘。
  - 匿名映射（`MAP_ANONYMOUS`）的生命周期与进程绑定，进程退出后自动释放。
- **同步机制**：若使用 `MAP_SHARED`，修改会同步到其他进程或文件。

#### **2. 核心 API**
```c
#include <sys/mman.h>

// 创建内存映射
void* mmap(void* addr, size_t length, int prot, int flags, int fd, off_t offset);

// 解除映射
int munmap(void* addr, size_t length);
```

#### **3. 使用示例**
```c
// 匿名共享内存（进程间共享）
int fd = -1; // 匿名映射无需文件
char* data = (char*)mmap(
    NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, fd, 0
);
sprintf(data, "Hello from PID %d", getpid());

// 映射文件到内存
int fd = open("data.bin", O_RDWR);
char* file_data = (char*)mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
munmap(file_data, 4096); // 解除映射
```

#### **4. 优点与缺点**
- **优点**：
  - 支持文件映射，实现内存与文件的透明同步。
  - 匿名映射适合临时共享内存，生命周期管理简单。
  - POSIX 标准，跨平台兼容性好。
- **缺点**：
  - 频繁的小文件映射可能产生性能开销。
  - 共享内存的同步需结合其他机制（如互斥锁）。


### **三、`shmget` 与 `mmap` 的关键对比**
| **特性**               | **`shmget` (System V)**          | **`mmap` (POSIX)**                  |
|-------------------------|----------------------------------|--------------------------------------|
| **标准**                | System V IPC                    | POSIX                                |
| **生命周期**            | 显式删除或系统重启             | 匿名映射随进程结束；文件映射可持久化 |
| **共享方式**            | 共享内存段                     | 文件映射或匿名内存                   |
| **同步机制**            | 需额外信号量                   | 可通过 `MAP_SHARED` 自动同步到文件   |
| **性能**                | 高（无文件 I/O 开销）          | 文件映射可能涉及磁盘 I/O             |
| **适用场景**            | 大规模进程间数据共享           | 文件操作或临时共享内存               |


### **四、选型建议**
1. **选择 `shmget` 的场景**：
   - 需要高性能、长期存在的共享内存。
   - 不依赖文件持久化，且需手动控制内存生命周期。

2. **选择 `mmap` 的场景**：
   - 需要将内存与文件同步（如内存数据库）。
   - 使用匿名映射快速创建临时共享内存。
   - 优先考虑 POSIX 标准兼容性。

### **五、高级用法：结合 `mmap` 与共享内存**
通过 `mmap` 实现 POSIX 共享内存（`shm_open`）：
```c
#include <sys/mman.h>
#include <sys/stat.h>
#include <fcntl.h>

int fd = shm_open("/my_shm", O_CREAT | O_RDWR, 0666); // 创建 POSIX 共享内存
ftruncate(fd, 4096);                                  // 设置大小
char* data = (char*)mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
sprintf(data, "Hello POSIX SHM");
munmap(data, 4096);
shm_unlink("/my_shm");                                // 删除共享内存对象
```


### **六、总结**
- **`shmget`**：适合传统的 System V 共享内存场景，需手动管理生命周期。
- **`mmap`**：更灵活，支持文件映射和匿名内存，符合现代 POSIX 标准。
- **混合使用**：结合 `shm_open`（POSIX 共享内存）与 `mmap`，兼顾标准化和性能。

---
## 进程和线程的区别，进程切换上下文的成本
在操作系统中，**进程（Process）** 和 **线程（Thread）** 是两种基本的并发执行单元，它们在资源管理、执行方式和上下文切换成本上有显著区别。以下是它们的详细对比及上下文切换成本的解释：


### **一、进程和线程的核心区别**
| **特性**               | **进程**                              | **线程**                              |
|------------------------|----------------------------------------|---------------------------------------|
| **定义**               | 资源分配的基本单位                      | CPU 调度的基本单位                     |
| **资源分配**           | 独立的内存空间、文件句柄等              | 共享所属进程的内存和资源               |
| **独立性**             | 进程间相互独立，崩溃不影响其他进程       | 线程属于同一进程，崩溃可能导致进程终止  |
| **通信方式**           | 进程间通信（IPC）：管道、消息队列等      | 直接共享进程内存，需同步机制（如锁）    |
| **创建和切换成本**     | 高（需分配独立资源）                    | 低（共享资源）                         |
| **安全性**             | 高（隔离性）                            | 低（共享内存易导致竞争条件）            |


### **二、进程切换上下文的成本**
#### 1. **什么是上下文切换？**
   - 上下文切换（Context Switching）是操作系统将 CPU 从一个进程（或线程）切换到另一个的过程。
   - 需要保存当前执行状态（如寄存器、程序计数器）并加载新状态。

#### 2. **进程切换的成本为何高？**
   - **虚拟内存切换**：
     - 进程有独立的虚拟地址空间，切换时需要更新页表基址寄存器（如 x86 的 `CR3`）。
     - 导致 **TLB（Translation Lookaside Buffer）失效**，降低内存访问效率。
   - **资源隔离**：
     - 进程切换需保存和恢复文件描述符、信号处理、用户权限等资源信息。
   - **缓存失效**：
     - CPU 缓存（Cache）中可能存有旧进程的数据，切换后缓存命中率下降。

#### 3. **线程切换的成本为何低？**
   - **共享内存空间**：
     - 线程属于同一进程，共享虚拟地址空间，无需切换页表。
   - **轻量级状态保存**：
     - 只需保存和恢复寄存器、栈指针等少量状态。
   - **缓存亲和性**：
     - 同一进程的线程共享缓存数据，切换后缓存仍可能有效。


### **三、上下文切换的具体开销**
1. **时间开销**：
   - **进程切换**：约 1-10 微秒（依赖硬件和操作系统）。
   - **线程切换**：约 0.1-1 微秒。
2. **性能影响**：
   - 频繁的上下文切换会导致 CPU 时间浪费在切换而非任务执行上，显著降低系统吞吐量。
   - 在极端高并发场景下（如每秒百万次切换），可能成为性能瓶颈。


### **四、如何减少上下文切换的开销？**
1. **优化并发模型**：
   - 使用线程池或协程（如 Goroutine）减少线程频繁创建和销毁。
   - 避免过多线程竞争 CPU（如合理设置线程池大小）。
2. **非阻塞 I/O**：
   - 使用异步 I/O（如 `epoll`、`kqueue`）减少线程因等待 I/O 而阻塞。
3. **共享内存通信**：
   - 进程间优先使用共享内存（而非管道或消息队列）减少数据拷贝。
4. **绑定 CPU 核心**：
   - 通过 CPU 亲和性（Affinity）将线程绑定到固定核心，提升缓存利用率。


### **五、进程和线程的适用场景**
| **场景**               | **推荐方式**                          | **原因**                              |
|------------------------|----------------------------------------|---------------------------------------|
| **需要高隔离性**       | 多进程                                 | 进程崩溃不影响其他进程                 |
| **频繁数据共享**       | 多线程                                 | 共享内存通信高效                       |
| **计算密集型任务**     | 多进程（避免 GIL 限制，如 Python）     | 利用多核 CPU 并行计算                  |
| **I/O 密集型任务**     | 多线程或协程                           | 减少等待 I/O 时的资源浪费              |


### **六、总结**
- **进程**：资源隔离性好，但创建和切换成本高，适合需要独立运行的任务。
- **线程**：共享资源、切换成本低，适合需要高效协作的任务。
- **上下文切换成本**：进程切换因涉及内存空间和资源切换，成本显著高于线程切换。

---
## 进程和线程的关系，一个进程一定拥有一个线程吗
**进程（Process）** 和 **线程（Thread）** 是操作系统中的两种并发执行单元，它们之间既有紧密的关系，也有显著的区别。以下是它们的详细关系及关于“一个进程是否一定拥有一个线程”的解答：


### **一、进程和线程的关系**
#### 1. **进程**
- **定义**：进程是操作系统资源分配的基本单位，拥有独立的内存空间、文件句柄、信号处理等资源。
- **特点**：
  - 进程间相互独立，一个进程崩溃不会影响其他进程。
  - 进程切换开销较大（涉及虚拟内存切换、资源保存等）。

#### 2. **线程**
- **定义**：线程是 CPU 调度的基本单位，属于某个进程，共享进程的资源（如内存、文件描述符）。
- **特点**：
  - 线程间共享进程资源，通信成本低。
  - 线程切换开销较小（只需保存和恢复寄存器、栈指针等）。

#### 3. **关系**
- **包含关系**：一个进程可以包含多个线程，这些线程共享进程的资源。
- **执行方式**：线程是进程内的执行流，多个线程可以并发执行。
- **资源管理**：进程负责资源分配，线程负责任务执行。


### **二、一个进程是否一定拥有一个线程？**
#### 1. **传统进程模型**
- 在早期的操作系统中，进程是单线程的，即一个进程只有一个执行流。
- 这种模型称为 **单线程进程**。

#### 2. **多线程进程模型**
- 现代操作系统支持多线程，一个进程可以包含多个线程。
- 这种模型称为 **多线程进程**。

#### 3. **结论**
- **一个进程至少拥有一个线程**，即主线程（Main Thread）。
- 主线程是进程启动时自动创建的，负责执行 `main()` 函数。
- 进程可以创建额外的线程（称为子线程），实现并发执行。


### **三、进程和线程的创建**
#### 1. **进程创建**
- 通过 `fork()` 系统调用创建子进程。
- 子进程是父进程的副本，拥有独立的内存空间和资源。

#### 2. **线程创建**
- 通过 `pthread_create()`（POSIX 线程）或 `std::thread`（C++11）创建线程。
- 线程共享进程的内存空间和资源。


### **四、示例**
#### 1. **单线程进程**
```c
#include <stdio.h>

int main() {
    printf("This is a single-threaded process.\n");
    return 0;
}
```

#### 2. **多线程进程**
```c
#include <stdio.h>
#include <pthread.h>

void* thread_func(void* arg) {
    printf("This is a child thread.\n");
    return NULL;
}

int main() {
    pthread_t tid;
    pthread_create(&tid, NULL, thread_func, NULL); // 创建子线程
    printf("This is the main thread.\n");
    pthread_join(tid, NULL); // 等待子线程结束
    return 0;
}
```

### **五、总结**
- **一个进程至少拥有一个线程**（主线程），可以创建多个线程实现并发。
- **进程**：资源分配的基本单位，拥有独立的内存空间。
- **线程**：CPU 调度的基本单位，共享进程的资源。

---
## 子进程和父进程的关系，fork的复制都是复制了什么？
在操作系统中，**子进程** 和 **父进程** 是通过 `fork()` 系统调用创建的两个相关进程。以下是它们的关系及 `fork()` 复制的内容的详细说明：

---

### **一、子进程和父进程的关系**
#### 1. **创建方式**
- 父进程通过 `fork()` 系统调用创建子进程。
- 子进程是父进程的副本，拥有独立的地址空间和资源。

#### 2. **关系**
- **父子关系**：
  - 子进程的父进程 ID（PPID）是父进程的进程 ID（PID）。
  - 父进程可以通过 `wait()` 或 `waitpid()` 等待子进程结束。
- **独立性**：
  - 子进程和父进程是独立的进程，修改子进程的资源不会影响父进程。
- **共享资源**：
  - 子进程继承父进程的文件描述符、信号处理等资源。

---

### **二、`fork()` 复制的内容**
`fork()` 创建子进程时，会复制父进程的以下内容：

#### 1. **地址空间**
- 子进程获得父进程地址空间的副本，包括：
  - 代码段（Text Segment）。
  - 数据段（Data Segment）。
  - 堆（Heap）。
  - 栈（Stack）。
- **写时复制（Copy-on-Write, COW）**：
  - 子进程和父进程共享物理内存，直到一方尝试修改数据时，才会复制内存页。

#### 2. **文件描述符**
- 子进程继承父进程打开的文件描述符，包括：
  - 文件偏移量。
  - 文件状态标志（如 `O_NONBLOCK`）。
- **共享文件表**：
  - 子进程和父进程共享文件表项，修改文件偏移量会影响另一方。

#### 3. **信号处理**
- 子进程继承父进程的信号处理函数和信号掩码。

#### 4. **环境变量**
- 子进程继承父进程的环境变量。

#### 5. **进程属性**
- 子进程继承父进程的以下属性：
  - 用户 ID 和组 ID。
  - 工作目录。
  - 资源限制（如 `RLIMIT_CPU`）。
  - 进程组 ID 和会话 ID。

#### 6. **未继承的内容**
- **进程 ID（PID）**：子进程有独立的 PID。
- **父进程 ID（PPID）**：子进程的 PPID 是父进程的 PID。
- **挂起的信号**：子进程不会继承父进程挂起的信号。
- **文件锁**：子进程不会继承父进程的文件锁。

---

### **三、`fork()` 的返回值**
- **父进程**：`fork()` 返回子进程的 PID。
- **子进程**：`fork()` 返回 `0`。
- **错误**：`fork()` 返回 `-1`，表示创建子进程失败。

#### 示例代码
```c
#include <stdio.h>
#include <unistd.h>

int main() {
    pid_t pid = fork(); // 创建子进程
    if (pid == 0) {
        // 子进程
        printf("Child process (PID: %d)\n", getpid());
    } else if (pid > 0) {
        // 父进程
        printf("Parent process (PID: %d), Child PID: %d\n", getpid(), pid);
    } else {
        // fork 失败
        perror("fork");
    }
    return 0;
}
```

---

### **四、`fork()` 的写时复制（COW）机制**
- **原理**：
  - `fork()` 创建子进程时，父子进程共享物理内存。
  - 当一方尝试修改内存时，操作系统会复制该内存页，确保修改不会影响另一方。
- **优点**：
  - 减少内存复制开销，提高 `fork()` 的性能。

---

### **五、总结**
- **子进程** 是父进程的副本，拥有独立的地址空间和资源。
- **`fork()`** 复制父进程的地址空间、文件描述符、信号处理等内容。
- **写时复制（COW）** 机制减少了内存复制开销，提高了 `fork()` 的效率。

---
## 子进程和线程的关系
**子进程** 和 **线程** 是操作系统中两种不同的并发执行单元，它们在资源管理、执行方式和通信机制上有显著区别。以下是它们的详细对比及关系说明：


### **一、子进程和线程的定义**
#### 1. **子进程**
- **定义**：通过 `fork()` 系统调用创建，是父进程的副本。
- **特点**：
  - 拥有独立的地址空间和资源。
  - 与父进程相互独立，修改子进程的资源不会影响父进程。
  - 进程间通信（IPC）需要通过管道、消息队列等机制。

#### 2. **线程**
- **定义**：通过 `pthread_create()` 或 `std::thread` 创建，是进程内的执行流。
- **特点**：
  - 共享进程的内存空间和资源。
  - 线程间可以直接共享数据，但需要同步机制（如互斥锁）避免竞争条件。
  - 线程切换开销较小。


### **二、子进程和线程的核心区别**
| **特性**               | **子进程**                            | **线程**                              |
|------------------------|----------------------------------------|---------------------------------------|
| **资源管理**           | 独立的内存空间和资源                   | 共享进程的内存和资源                  |
| **独立性**             | 进程间相互独立，崩溃不影响其他进程       | 线程属于同一进程，崩溃可能导致进程终止  |
| **通信方式**           | 进程间通信（IPC）：管道、消息队列等      | 直接共享进程内存，需同步机制（如锁）    |
| **创建和切换成本**     | 高（需分配独立资源）                    | 低（共享资源）                         |
| **安全性**             | 高（隔离性）                            | 低（共享内存易导致竞争条件）            |


### **三、子进程和线程的关系**
#### 1. **资源共享**
- **子进程**：不共享父进程的内存空间，资源独立。
- **线程**：共享所属进程的内存空间和资源。

#### 2. **执行方式**
- **子进程**：独立执行，与父进程并发运行。
- **线程**：在进程内并发执行，共享进程的上下文。

#### 3. **通信机制**
- **子进程**：需要通过 IPC 机制（如管道、共享内存）通信。
- **线程**：可以直接共享内存，但需要同步机制（如互斥锁）避免竞争条件。

#### 4. **崩溃影响**
- **子进程**：崩溃不会影响父进程或其他子进程。
- **线程**：崩溃可能导致整个进程终止。


### **四、示例代码**
#### 1. **子进程示例**
```c
#include <stdio.h>
#include <unistd.h>

int main() {
    pid_t pid = fork(); // 创建子进程
    if (pid == 0) {
        // 子进程
        printf("Child process (PID: %d)\n", getpid());
    } else if (pid > 0) {
        // 父进程
        printf("Parent process (PID: %d), Child PID: %d\n", getpid(), pid);
    } else {
        // fork 失败
        perror("fork");
    }
    return 0;
}
```

#### 2. **线程示例**
```c
#include <stdio.h>
#include <pthread.h>

void* thread_func(void* arg) {
    printf("Child thread (TID: %lu)\n", pthread_self());
    return NULL;
}

int main() {
    pthread_t tid;
    pthread_create(&tid, NULL, thread_func, NULL); // 创建线程
    printf("Main thread (TID: %lu)\n", pthread_self());
    pthread_join(tid, NULL); // 等待线程结束
    return 0;
}
```


### **五、适用场景**
| **场景**               | **推荐方式**                          | **原因**                              |
|------------------------|----------------------------------------|---------------------------------------|
| **需要高隔离性**       | 多进程                                 | 进程崩溃不影响其他进程                 |
| **频繁数据共享**       | 多线程                                 | 共享内存通信高效                       |
| **计算密集型任务**     | 多进程（避免 GIL 限制，如 Python）     | 利用多核 CPU 并行计算                  |
| **I/O 密集型任务**     | 多线程或协程                           | 减少等待 I/O 时的资源浪费              |


### **六、总结**
- **子进程**：资源独立，适合需要高隔离性的场景。
- **线程**：资源共享，适合需要高效协作的场景。
- **选择依据**：根据任务特点（如隔离性、数据共享需求）选择合适的并发模型。