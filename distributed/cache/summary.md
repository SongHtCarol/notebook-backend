# 分布式缓存

- [分布式缓存](#分布式缓存)
    - [缓存](#缓存)
    - [缓存技术中的几个术语](#缓存技术中的几个术语)
    - [客户端缓存](#客户端缓存)
      - [页面缓存](#页面缓存)
      - [浏览器缓存](#浏览器缓存)
      - [APP上的缓存](#app上的缓存)
    - [网络中的缓存](#网络中的缓存)
      - [Web代理缓存](#web代理缓存)
        - [正向代理](#正向代理)
        - [反向代理](#反向代理)
        - [透明代理](#透明代理)
      - [边缘缓存](#边缘缓存)
    - [服务端缓存](#服务端缓存)
      - [数据库缓存](#数据库缓存)
      - [平台级缓存](#平台级缓存)
      - [应用级缓存](#应用级缓存)
    - [引入缓存](#引入缓存)
      - [引入缓存前的考量](#引入缓存前的考量)
      - [缓存知识地图](#缓存知识地图)
      - [常见的缓存组件](#常见的缓存组件)
      - [缓存架构设计](#缓存架构设计)
      - [缓存分类](#缓存分类)
      - [缓存使用模式](#缓存使用模式)
      - [缓存协议](#缓存协议)
      - [缓存连接池](#缓存连接池)
      - [几个关注点](#几个关注点)
        - [集群组建方式](#集群组建方式)
        - [统计](#统计)
        - [序列化](#序列化)
        - [缓存命中率](#缓存命中率)
        - [提高缓存命中率的方法](#提高缓存命中率的方法)
    - [管理缓存](#管理缓存)
      - [缓存穿透](#缓存穿透)
      - [缓存失效](#缓存失效)
      - [淘汰算法](#淘汰算法)
    - [缓存可用性](#缓存可用性)
    - [数据一致性](#数据一致性)
    - [热点数据处理](#热点数据处理)
      - [数据预热](#数据预热)
      - [非预期热点策略](#非预期热点策略)
      - [多级缓存模式](#多级缓存模式)
      - [数据复制模式](#数据复制模式)
    - [其他](#其他)

---
### 缓存
```
存储在计算机上的一个原始数据复制集
```
- 优化用户体验
- 优化系统性能

### 缓存技术中的几个术语
- 缓存命中：cache hit
- 没有命中：cache miss
- 存储成本：没有缓存命中时，将数据放入缓存所需要的时间和空间
- 缓存失效：存储在缓存中的数据需要更新时
- 替代策略：当缓存没有命中时，且缓存的容量已经满了，需要在缓存中去除一条旧数据，然后加入一条新数据。去除哪一条数据，由替代算法决定
  - LRU（Least- Recently-Used）：替换掉最近被请求最少的对象。将最新被访问的缓存对象放到缓存池顶部
  - LFU（Least- Frequently-Used）：替换掉访问次数最少的缓存。缺点是会造成缓存污染，因为没有策略替换掉历史上使用频率很高的数据，阻碍了新的可能使用频率很高的数据进入缓存
  - LRU2（Least- Recently-Used2）：替换掉两次最少使用的缓存对象。需要跟踪对象两次，将两次访问过的对象放入缓存
  - 2Q （Two Queues）：把被访问的数据放到LRU的缓存中，如果这个对象再一次被访问，就把它转移到第二个、更大的LRU缓存
  - SIZE：替换占用空间最大的对象。有些小的缓存数据，永远不再被访问，也不会被踢出缓存，造成缓存污染
  - LRU-Threshold：不缓存超过某一size的对象，其他与LRU相同
  - Log（size）+LRU：替换size最大的对象，当size相同时，按LRU进行替换
  - Hyper-G：LRU的改进版，同时考虑上次访问时间和对象size
  - Pitkow/Recker：替换最近最少使用的对象。如果所有对象都是今天访问过的，替换掉最大的对象。
  - Lowest-Latency-First：替换下载时间最少的文档，目标是最小化平均延迟
  - Hybrid Hybird
  - MRU（Most Recently Used）：替换掉最近最多被使用的对象
  - FIFO（First In First Out）：最近最常使用的缓存会放在队列后面
  - Random Cache：随机替换缓存数据

### 客户端缓存
#### 页面缓存
- 页面自身对某些元素或者全部元素进行缓存
- 用户再次访问时可以避开网络连接，减少负载，加速响应
- HTML5支持了离线缓存(manifest)和本地存储(localStorage)

#### 浏览器缓存
- 浏览器会在硬盘上专门开辟一个空间来存储资源副本作为缓存
- HTTP1.0 服务器设置`Expires`的HTTP头，客户端通过 `if-modified-since`的条件请求来使用缓存。文件没有变化，服务器用`304-Not Modified`应答
- HTTP1.1 引入实体标签`e-tag`，如果一个文件或者对象的`e-tag`是有效的，那么服务器会生成`304-Not Modified`应答，并提供正确文件的`e-tag`。否则，发送`200-OK`应答
- `Cache-Control/Expires`的优先级高于`Last-Modified/ETag`


<table>
  <tr>
    <th>用户行为</th>
    <th>Cache-Control/Expires</th>
    <th>Last-Modified/ETag</th>
  </tr>
  <tr>
    <td>地址栏回车</td>
    <td>Y</td>
    <td>Y</td>
  </tr>
  <tr>
    <td>链接跳转</td>
    <td>Y</td>
    <td>Y</td>
  </tr>
    <tr>
    <td>新开窗口</td>
    <td>Y</td>
    <td>Y</td>
  </tr>
    <tr>
    <td>前进后退</td>
    <td>Y</td>
    <td>Y</td>
  </tr>
    <tr>
    <td>F5刷新</td>
    <td>N</td>
    <td>Y</td>
  </tr>
      <tr>
    <td>Ctrl+F5刷新</td>
    <td>N</td>
    <td>N</td>
  </tr>
</table>

#### APP上的缓存
- APP可以将内容缓存在内存、文件或本地数据库中
- 下载数据文件后，把文件的相关信息，如URL、路径、下载时间、过期时间等存放到数据库
- 不同环境下缓存时间标准不同，比如：Wifi环境下，缓存时间可以设置短一点；移动数据环境下，缓存时间可以设置长一点，节省流量，用户体验更好
- 不同操作系统下缓存机制不同

### 网络中的缓存

```
网络中的缓存位于客户端与服务端之间，代理或响应客户端的网络请求，从而对重复的请求返回缓存中的数据资源。
```

#### Web代理缓存
##### 正向代理
- 用户向代理服务器发送请求
- 用户的请求中指定目标服务器
- 代理服务器向源服务器转交请求
- 代理服务器将获得的内容返回给客户端
- 客户端需要进行特别的设置才能使用正向代理

##### 反向代理
- 用户向代理服务器发送请求
- 反向代理判断向何处转发请求
- 代理服务器将获得的内容返回给客户端
- 客户端不需要进行特别的设置
- 例如：Nginx

##### 透明代理
- 客户端不需要知道有代理服务器的存在
- 代理服务器改变客户端请求的报文字段，并传送真实的IP地址


#### 边缘缓存
- 位于靠近用户的一侧，主要用于向用户提供静态内容，减少服务器介入
- 例如：CDN
- HTTP响应头中的 `Cache-control:max-age` 字段来设置CDN边缘节点的数据缓存时间

### 服务端缓存
#### 数据库缓存
- 数据库自身的缓存机制
- 例如：MySQL查询缓冲机制、缓存表
#### 平台级缓存
```
指用来写带有缓存特性的应用框架，或者可用于缓存功能的专用库
```
#### 应用级缓存
```
开发者通过代码来实现缓存机制
```
- Redis
- MongoDB
- Memcached
- ... (NoSQL)


### 引入缓存
#### 引入缓存前的考量
根据业务的应用规模、访问量级决定是否需要引入缓存。
- 规模不大，数据量和访问量都不大的系统，引入缓存并不能带来明显的性能提升。
- 对于单条数据较大的业务，如图片系统，更加的选择可能是分布式文件系统而非缓存
- 对于具有一定规模的常规业务系统，数据规模和访问量都较大，且持续增加。要保证服务稳定性，在突发流量下也能快速响应用户，可以考虑引入缓存

#### 缓存知识地图
<img src='/distributed/img/cache.png'>


#### 常见的缓存组件
<table>
    <tr>
        <th>缓存组件</th>
        <th>数据类型</th>
        <th>访问方式</th>
        <th>数据容量(单实例)</th>
        <th>数据同步方式</th>
        <th>内存效率</th>
    </tr>
    <tr>
        <td>Memcached</td>
        <td>简单KV</td>
        <td>Get/Set等常规接口</td>
        <td>100GB以下</td>
        <td>Client多写</td>
        <td>一般</td>
    </tr>
    <tr>
        <td>Redis</td>
        <td>丰富</td>
        <td>更丰富的常规接口</td>
        <td>30GB以下</td>
        <td>主从复制</td>
        <td>一般</td>
    </tr>
    <tr>
        <td>Pika/ssdb</td>
        <td>较redis丰富</td>
        <td>丰富</td>
        <td>数百GB以上</td>
        <td>主从复制</td>
        <td>一般</td>
    </tr>
</table>

#### 缓存架构设计
<img src='/distributed/img/cache design.png'>

#### 缓存分类
```
二级缓存存在热key或者大key等难以解决的问题，可以通过本地缓存来有效的解决
```
<img src='/distributed/img/cache classification.png'>

#### 缓存使用模式
<img src='/distributed/img/cache usage.png'>

#### 缓存协议
<img src='/distributed/img/cache protocol.png'>

#### 缓存连接池
连接池的实现主要依赖于集群方式和底层IO机制。
- 集群方式
  - 单点
  - sharding
  - cluster
- 底层IO
  - BIO
  - NIO

常用的缓存客户端
- Jedis
  - Redis客户端
  - 基于common-pool
- Spymemcached
  - Memcached客户端
  - IO为NIO的实现
  - 客户端实现了连接的多路复用

#### 几个关注点
##### 集群组建方式
1. 客户端sharding
   1. key在客户端通过hash进行sharding
   2. 服务端运维简单
   3. 客户端需要实现动态的扩缩容机制
2. proxy
   1. proxy实现对后端缓存服务的集群管理
   2. proxy也是一个集群
   3. 运维复杂
   4. 扩展性强
   5. 可以在proxy层面实现限流等功能
3. 服务端集群
   1. 主要是Redis的cluster机制，基于Gossip协议实现
##### 统计
<table>
    <tr>
        <th>监控项</th>
        <th>说明</th>
    </tr>
    <tr>
        <td>uptime</td>
        <td>启动总时长</td>
    </tr>
    <tr>
        <td>total mem</td>
        <td>总分配内存量</td>
    </tr>
    <tr>
        <td>used mem</td>
        <td>已使用内存量</td>
    </tr>
    <tr>
        <td>free mem</td>
        <td>可用内存量</td>
    </tr>
    <tr>
        <td>keys count</td>
        <td>缓存对象总数</td>
    </tr>
    <tr>
        <td>total commands</td>
        <td>总计执行命令数</td>
    </tr>
    <tr>
        <td>hits/s</td>
        <td>每秒命中数</td>
    </tr>
    <tr>
        <td>miss/s</td>
        <td>每秒未命中数</td>
    </tr>
    <tr>
        <td>expire/s</td>
        <td>每秒失效数量</td>
    </tr>
    <tr>
        <td>slow query</td>
        <td>慢查询</td>
    </tr>
 </table>   

##### 序列化
访问缓存需要进行序列化和反序列化。Redis或者Memcached存储的都是字节类型的数据。

序列化性能考量
- 序列化的时间
  - 层级比较深的对象结构，或者字段比较多的对象，不同的序列化机制，序列化时间有较大差异
- 序列化之后包的大小
  - 序列化之后的包越小，网络传输越快，占用存储空间越小
- 序列化的开销
  - 序列化后的数据，在获取的时候会进行反序列化。
  - 反序列化带来的CPU消耗特别大

##### 缓存命中率
- 命中：直接通过缓存获取数据
- 不命中：无法直接通过缓存获取数据
  - 缓存中不存在
  - 缓存已过期

影响缓存命中率的几个因素
- 业务场景和业务需求
  - 缓存适合读多写少的业务场景
  - 业务需求决定了时效要求，影响缓存的过期时间和更新策略。时效性要求越低，越适合缓存
- 缓存数据粒度
  - 缓存粒度越小，命中率越高
- 缓存容量和基础设施
  - 缓存容量有限，容易引起缓存失效和被淘汰
  - 采用本地缓存容易出现单机瓶颈
  - 采用分布式缓存容易扩展
  - 不同的缓存框架或者中间件，效率和稳定性也有差异
- 其他因素
  - 缓存节点发生故障时，需要避免缓存失效并最大程度降低影响。比如：一致性哈希、节点冗余
  - 在相同缓存时间和key的情况下，并发越高，缓存收益越高

##### 提高缓存命中率的方法
- 缓存预热
- 增加容量
- 调整缓存粒度
- 选择合适的更新缓存策略

### 管理缓存
#### 缓存穿透
- 大量请求不存在的key
  - 缓存nokey
- 并发量较大的业务，一个缓存失效，多个进程同时查db，同时设置缓存。可以考虑查询缓存时加锁的方案。但是锁的逻辑放在client还是server需要考量。
#### 缓存失效
- 高并发的场景下，如果缓存过期时间都相同，可能会出现某个时间段内的大量缓存数据同时过期
- 此时请求全部转发到db，对存储造成很大压力
- 离散化缓存过期时间，在原有的失效时间上加一个随机值
#### 淘汰算法
- LRU
  - LRU：最近最少使用
  - LRU-K：最近使用过K次
  - Two Queues：两个缓存队列，一个FIFO队列，一个LRU队列
  - Multi Queues：根据访问频率将数据划分为多个队列，不同的队列有不同的优先级
- LFU
  - LFU：根据数据的历史访问频率来淘汰数据
  - LFU*：只淘汰访问过一次的数据
  - LFU-Aging：除了访问次数外，还要考虑访问时间
  - LFU*-Aging：LFU*和LFU-Aging的合体
  - Window-LFU：不记录所有数据的访问历史，只记录过去一段时间内的访问历史
- FIFO
  - FIFO：先进先出
  - Second Chance：如果被淘汰的数据之前被访问过，则给第二次机会
  - Clock：通过一个环形队列，避免将数据在FIFO队列中移动

### 缓存可用性
- 主备方案
- cluster方案
### 数据一致性
- 最终一致性
  - 写缓存失败，补偿到一致(Facebook案例)
  <img src='/distributed/img/facebook.jpg'>
- 强一致性
  - innodb memcached
  <img src='/distributed/img/innodb memcached.jpg'>
### 热点数据处理
#### 数据预热
提前把数据读入到缓存。
细节问题：
- 是否有监控机制确保预热数据都写成功了
- 数据预热配备回滚方案
- 预热数据量的考量
- 预热过程中需要注意是否会因为批量数据库操作或慢sql引发数据库性能问题
#### 非预期热点策略
- 一般建立实时热点发现系统来发现热点
- 发现热key推到本地缓存，满足离用户最近原则
#### 多级缓存模式
- 一旦某个热点出发了一台机器的限流阈值，这台机器的cache数据都将无效，进而导致cache被击穿，请求落到数据库发生雪崩。
- 通用的解决思路：在cache的client端做本地cache，当发现热点数据的时候直接cache在client端，不向server请求
#### 数据复制模式
- facebook的做法：`key:xxx#N` 热点key发布到所有服务器上，在每个服务器有别名；读的时候按照相同的路由算法获取某台服务器上的数据。
### 其他
1. 慎把缓存当存储，缓存不可用时是否能够容忍
2. 缓存就近原则
   1. cpu缓存
     <img src='/distributed/img/cpu cache.jpg'>
   2. 客户端缓存
   3. CDN缓存
3. 并发控制手段
   1. 乐观锁（版本号）
   2. mutex
   3. CAS